{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required packages \n",
    "#-------------------------\n",
    "\n",
    "# Import the Logistic Regression Module from Scikit Learn\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "\n",
    "# Import the IRIS Dataset to be used in this Kernel\n",
    "from sklearn.datasets import load_iris  \n",
    "\n",
    "# Load the Module to split the Dataset into Train & Test \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "Iris_data = load_iris() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(Iris_data.data, \n",
    "                                                Iris_data.target, \n",
    "                                                test_size=0.3, \n",
    "                                                random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=20,\n",
       "                   multi_class='warn', n_jobs=3, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Model\n",
    "LR_Model = LogisticRegression(C=0.1,  \n",
    "                               max_iter=20, \n",
    "                               fit_intercept=True, \n",
    "                               n_jobs=3, \n",
    "                               solver='liblinear')\n",
    "\n",
    "# Train the Model\n",
    "LR_Model.fit(Xtrain, Ytrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Way to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickle Package\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Modle to file in the current working directory\n",
    "\n",
    "Pkl_Filename = \"Pickle_RL_Model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(LR_Model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=20,\n",
       "                   multi_class='warn', n_jobs=3, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    Pickled_LR_Model = pickle.load(file)\n",
    "\n",
    "Pickled_LR_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 91.11 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2,\n",
       "       1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 1, 1, 0, 2, 0, 1, 0,\n",
       "       2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the Reloaded Model to \n",
    "# Calculate the accuracy score and predict target values\n",
    "\n",
    "# Calculate the Score \n",
    "score = Pickled_LR_Model.score(Xtest, Ytest)  \n",
    "# Print the Score\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "\n",
    "# Predict the Labels using the reloaded Model\n",
    "Ypredict = Pickled_LR_Model.predict(Xtest)  \n",
    "\n",
    "Ypredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import Joblib Module from Scikit Learn\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joblib_RL_Model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save RL_Model to file in the current working directory\n",
    "\n",
    "joblib_file = \"joblib_RL_Model.pkl\"  \n",
    "joblib.dump(LR_Model, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=20,\n",
       "                   multi_class='warn', n_jobs=3, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from file\n",
    "\n",
    "joblib_LR_model = joblib.load(joblib_file)\n",
    "\n",
    "\n",
    "joblib_LR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 91.11 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2,\n",
       "       1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 1, 2, 2, 1, 1, 0, 2, 0, 1, 0,\n",
       "       2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the Reloaded Joblib Model to \n",
    "# Calculate the accuracy score and predict target values\n",
    "\n",
    "# Calculate the Score \n",
    "score = joblib_LR_model.score(Xtest, Ytest)  \n",
    "# Print the Score\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "\n",
    "# Predict the Labels using the reloaded Model\n",
    "Ypredict = joblib_LR_model.predict(Xtest)  \n",
    "\n",
    "Ypredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize model for saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "import json  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogReg(LogisticRegression):\n",
    "\n",
    "    # Override the class constructor\n",
    "    def __init__(self, C=1.0, solver='liblinear', max_iter=100, X_train=None, Y_train=None):\n",
    "        LogisticRegression.__init__(self, C=C, solver=solver, max_iter=max_iter)\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "\n",
    "    # A method for saving object data to JSON file\n",
    "    def save_json(self, filepath):\n",
    "        dict_ = {}\n",
    "        dict_['C'] = self.C\n",
    "        dict_['max_iter'] = self.max_iter\n",
    "        dict_['solver'] = self.solver\n",
    "        dict_['X_train'] = self.X_train.tolist() if self.X_train is not None else 'None'\n",
    "        dict_['Y_train'] = self.Y_train.tolist() if self.Y_train is not None else 'None'\n",
    "\n",
    "        # Creat json and save to file\n",
    "        json_txt = json.dumps(dict_, indent=4)\n",
    "        with open(filepath, 'w') as file:\n",
    "            file.write(json_txt)\n",
    "\n",
    "    # A method for loading data from JSON file\n",
    "    def load_json(self, filepath):\n",
    "        with open(filepath, 'r') as file:\n",
    "            dict_ = json.load(file)\n",
    "\n",
    "        self.C = dict_['C']\n",
    "        self.max_iter = dict_['max_iter']\n",
    "        self.solver = dict_['solver']\n",
    "        self.X_train = np.asarray(dict_['X_train']) if dict_['X_train'] != 'None' else None\n",
    "        self.Y_train = np.asarray(dict_['Y_train']) if dict_['Y_train'] != 'None' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLogReg(C=1.0,\n",
       "         X_train=array([[4.3, 3. , 1.1, 0.1],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [6.4...\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.7, 2.8, 6.7, 2. ]]),\n",
       "         Y_train=array([0, 0, 1, 1, 2, 0, 1, 2, 2, 1, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2, 1, 2,\n",
       "       1, 0, 2, 2, 0, 1, 2, 0, 2, 1, 2, 1, 0, 2, 1, 2, 0, 2, 1, 2, 1, 2,\n",
       "       1, 1, 2, 1, 1, 2, 1, 1, 0, 2, 0, 1, 0, 1, 1, 1, 1, 0, 2, 2, 1, 1,\n",
       "       1, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 2, 1, 0, 0, 2,\n",
       "       1, 2, 0, 0, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2]),\n",
       "         max_iter=100, solver='liblinear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"mylogreg.json\"\n",
    "\n",
    "# Create a model and train it\n",
    "mylogreg = MyLogReg(X_train=Xtrain, Y_train=Ytrain)  \n",
    "mylogreg.save_json(filepath)\n",
    "\n",
    "# Create a new object and load its data from JSON file\n",
    "json_mylogreg = MyLogReg()  \n",
    "json_mylogreg.load_json(filepath)  \n",
    "json_mylogreg  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
